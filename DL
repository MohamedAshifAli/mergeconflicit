import cv2
import numpy as np
from glob import glob
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
import seaborn as sns
from keras.models import Sequential
from keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense
from keras.optimizers import Adam
from keras.preprocessing.image import ImageDataGenerator

# Define the image processing functions (LBP and LTP)
def get_pixel(img, center, x, y):
    if center < img[x][y]:
        s = 1
    else:
        s = 0
    return s

def calculate_LBP(img, x, y):
    # Implementation of Local Binary Pattern (LBP)
    # Code for calculate_LBP function goes here

def LBP(img):
    # Implementation of Local Binary Pattern (LBP)
    # Code for LBP function goes here

def get_upper_pixel(img, center, x, y, t):
    # Implementation of get_upper_pixel function
    # Code for get_upper_pixel function goes here

def get_lower_pixel(img, center, x, y, t):
    # Implementation of get_lower_pixel function
    # Code for get_lower_pixel function goes here

def ltp_calculated_pixel_upper(img, x, y, t):
    # Implementation of ltp_calculated_pixel_upper function
    # Code for ltp_calculated_pixel_upper function goes here

def ltp_calculated_pixel_lower(img, x, y, t):
    # Implementation of ltp_calculated_pixel_lower function
    # Code for ltp_calculated_pixel_lower function goes here

def LTP(img):
    # Implementation of Local Ternary Pattern (LTP)
    # Code for LTP function goes here

# Load datasets using glob
count = 1
datasets = glob("Dataset\\**\\*.*")
faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_alt2.xml")

# Define the image processing function
def image_process(datasets):
    # Implementation of image processing function
    # Code for image_process function goes here

# Call the image processing function
path = "Dataset"
getallvideo = glob(path + '/**/*.mp4')
process_Imaging = image_process(getallvideo)

# Machine Learning Model Training and Evaluation
# Put labels into y_train variable
Y_train = train["label"]
# Drop 'label' column
X_train = train.drop(labels=["label"], axis=1)
# Reshape
X_train = X_train.values.reshape(-1, 28, 28, 1)
test = test.values.reshape(-1, 28, 28, 1)
print("x_train shape: ", X_train.shape)
print("test shape: ", test.shape)

# Split the train and the validation set for the fitting
X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=2)
print("x_train shape", X_train.shape)
print("x_test shape", X_val.shape)
print("y_train shape", Y_train.shape)
print("y_test shape", Y_val.shape)

plt.imshow(X_train[2][:, :, 0], cmap='gray')
plt.show()

# Define the CNN model
model = Sequential()
model.add(Conv2D(filters=8, kernel_size=(5, 5), padding='Same', activation='relu', input_shape=(28, 28, 1)))
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Conv2D(filters=16, kernel_size=(3, 3), padding='Same', activation='relu'))
model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(256, activation="relu"))
model.add(Dropout(0.5))
model.add(Dense(10, activation="softmax"))
optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)
model.compile(optimizer=optimizer, loss="categorical_crossentropy", metrics=["accuracy"])

# Data augmentation
datagen = ImageDataGenerator(
    featurewise_center=False,
    samplewise_center=False,
    featurewise_std_normalization=False,
    samplewise_std_normalization=False,
    zca_whitening=False,
    rotation_range=5,
    zoom_range=0.1,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=False,
    vertical_flip=False
)
datagen.fit(X_train)

# Fit the model
batch_size = 32
epochs = 10
history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),
                              epochs=epochs, validation_data=(X_val, Y_val),
                              steps_per_epoch=X_train.shape[0] // batch_size)

# Plot validation loss
plt.plot(history.history['val_loss'], color='b', label="validation loss")
plt.title("Test Loss")
plt.xlabel("Number of Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

# Predictions and Confusion Matrix
Y_pred = model.predict(X_val)
Y_pred_classes = np.argmax(Y_pred, axis=1)
Y_true = np.argmax(Y_val, axis=1)
confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)
f, ax = plt.subplots(figsize=(8, 8))
sns.heatmap(confusion_mtx, annot=True, linewidths=0.01, cmap="Greens", linecolor="gray", fmt='.1f', ax=ax)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()
