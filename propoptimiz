import numpy as np
from copy import deepcopy
from mealpy.optimizer import Optimizer

class BaseProp(Optimizer):
    ID_POS = 0
    ID_TAR = 1
    ID_VEC = 2  # Velocity
    ID_LOP = 3  # Local position
    ID_LOF = 4  # Local fitness

    def __init__(self, problem, epoch=10000, pop_size=100, c1=2.05, c2=2.05, w_min=0.4, w_max=0.9, **kwargs):
        """
        Args:
            problem (dict): The problem dictionary
            epoch (int): maximum number of iterations, default = 10000
            pop_size (int): number of population size, default = 100
            c1 (float): [0-2] local coefficient
            c2 (float): [0-2] global coefficient
            w_min (float): Weight min of bird, default = 0.4
            w_max (float): Weight max of bird, default = 0.9
        """
        super().__init__(problem, kwargs)
        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
        self.c1 = self.validator.check_float("c1", c1, (0, 5.0))
        self.c2 = self.validator.check_float("c2", c2, (0, 5.0))
        self.w_min = self.validator.check_float("w_min", w_min, (0, 0.5))
        self.w_max = self.validator.check_float("w_max", w_max, [0.5, 2.0])

        self.nfe_per_epoch = self.pop_size
        self.sort_flag = False
        self.v_max = 0.5 * (self.problem.ub - self.problem.lb)
        self.v_min = -self.v_max
        self.ST = 0.8 ## Safety Threshold Value

    def create_solution(self, lb=None, ub=None, pos=None):
        """
        Overriding method in Optimizer class

        Returns:
            list: wrapper of solution with format [position, target, velocity, local_pos, local_fit]
        """
        if pos is None:
            pos = self.generate_position(lb, ub)
        position = self.amend_position(pos, lb, ub)
        target = self.get_target_wrapper(position)
        velocity = np.random.uniform(self.v_min, self.v_max)
        local_pos = deepcopy(position)
        local_fit = deepcopy(target)
        return [position, target, velocity, local_pos, local_fit]

    def amend_position(self, position=None, lb=None, ub=None):
        """
        Args:
            position: vector position (location) of the solution.
            lb: list of lower bound values
            ub: list of upper bound values

        Returns:
            Amended position (make the position is in bound)
        """
        condition = np.logical_and(lb <= position, position <= ub)
        pos_rand = np.random.uniform(lb, ub)
        return np.where(condition, position, pos_rand)

    def evolve(self, epoch):
        """
        The main operations (equations) of algorithm. Inherit from Optimizer class

        Args:
            epoch (int): The current iteration
        """
        # Update weight after each move count  (weight down)
        w = (self.epoch - epoch) / self.epoch * (self.w_max - self.w_min) + self.w_min
        levyBeta = self.get_levy_flight_step(beta=1.5, multiplier=0.05, size=(self.pop_size, self.problem.n_dims), case=-1)
        t=1
        for idx in range(0, self.pop_size):
            agent = deepcopy(self.pop[idx])
            k = np.random.rand()  ##Early Warning Value
            f1=np.random.rand()
            f2=np.random.rand()
            Xt = self.pop[idx][self.ID_POS]
            Xg=self.g_best[self.ID_POS]
            ep1=np.random.rand()
            ep2=np.random.rand()
            r2=np.random.rand()
            Dt=np.random.rand()
            e= self.pop[idx][self.ID_POS]
            if idx==0:
                Xt2=self.pop[idx][self.ID_POS]
            else:
                Xt2 = self.pop[idx-1][self.ID_POS]
            if k<self.ST:
                ## Safety Phase Equation Case 1
                ## Then the group enviornment is in safe state no predator is nearby. so the searcher carry out extensive search
                ## Mechanishm for finding the food. At that time the position of searcher
                Xt =Xt + t *levyBeta[idx]
            else:
                if f1 >f2:
                    Xt = 2.718*(Xt -Xt2)-r2*e+ Dt* (Xg-Xt)  ## updated Equation
                else:
                    Xt = 0.5*(2*Xt+w+r2*e-Dt*(Xg-Xt)+self.c1*ep1*(Xg-Xt)+self.c2*ep2*(Xg-Xt)) #updated Equation
            v_new = w * self.pop[idx][self.ID_VEC] + self.c1 * np.random.rand() * \
                    (self.pop[idx][self.ID_LOP] - self.pop[idx][self.ID_POS]) + \
                    self.c2 * np.random.rand() * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
            x_new = self.pop[idx][self.ID_POS] + Xt
            pos_new = self.amend_position(x_new, self.problem.lb, self.problem.ub)
            target = self.get_target_wrapper(pos_new)
            agent[self.ID_POS] = pos_new
            agent[self.ID_VEC] = v_new
            agent[self.ID_TAR] = target
            if self.compare_agent([pos_new, target], [None, self.pop[idx][self.ID_TAR]]):
                agent[self.ID_LOP] = pos_new
                agent[self.ID_LOF] = target
            self.pop[idx] = self.get_better_solution(self.pop[idx], agent)
            t=t+1
