import numpy as np
import pandas as pd# evaluate model performance with outliers removed using isolation forest
from imblearn.over_sampling import SMOTE
from pandas import read_csv

from sklearn.ensemble import IsolationForest
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.linear_model import LinearRegression

import torch
import torch.nn as nn
import torch.optim as optim

# read the CSV file into a DataFrame

# load the dataset


# # Health = pd.read_csv("Datasets/Life_Expectancy_Data.csv")
# def coloumn_values_to_integer(features):
#     label_encoder = LabelEncoder()
#     for column in features.columns:
#         if features[column].dtype == 'object':
#             try:
#                 features[column] = label_encoder.fit_transform(features[column])
#             except:
#                 features[column] = label_encoder.fit_transform(features[column].astype("str"))
#     return features
# def outlier(features):
#
#     iso = IsolationForest(contamination=0.1)
#     yhat = iso.fit_predict(features)
#     unique_values, counts = np.unique(yhat, return_counts=True)
#     outlier_ind = np.max(yhat)
#     features['Outlier_Label'] = yhat
#     features = features[yhat == outlier_ind]
#     return features
# def traffic_data_preprocess():
#
#     traffic_data = pd.read_csv("New Folder/traffic.csv")
#     traffic_data.head()
#
#     traffic_data['DateTime']=pd.to_datetime(traffic_data['DateTime'])
#
#     traffic_data["Year"]=traffic_data['DateTime'].dt.year
#
#     traffic_data["Month"]=traffic_data['DateTime'].dt.month
#
#     traffic_data["Date_no"]=traffic_data['DateTime'].dt.day
#
#     traffic_data["Hour"]=traffic_data['DateTime'].dt.hour
#
#     traffic_data["Day"]= traffic_data['DateTime'].dt.strftime("%A")
#
#     traffic_data.drop("DateTime", axis=1, inplace=True)
#
#
#     traffic_data.dropna()
#     traffic_data.drop_duplicates()
#
#
#     features = coloumn_values_to_integer(traffic_data)
#     features =outlier(features)
#     features = features.drop(columns=['Outlier_Label'])
#
#     labels = features['Vehicles']
#
#
#     return features,labels
#
# features,labels = traffic_data_preprocess()
# xtrain, xtest, ytrain, ytest= train_test_split(features, labels, test_size=0.33, random_state=42)
#
# print()

#Air
df = pd.read_csv("New Folder/AirQuality.csv", sep=";", decimal=",")
sns.heatmap(df.isna(),yticklabels=False,cmap='crest')
plt.show()





print()







# #air quality
# df = pd.read_csv("Datasets/AirQuality.csv",sep=";", decimal=",")
# # Remove unnecessary columns
# df = df.drop(['Unnamed: 15','Unnamed: 16'], axis = 1)
# df.isnull().sum()
# df = df.dropna()
# df = df.duplicated().sum()
# print()
#
# #Health
# df1 = pd.read_csv("Datasets/Life_Expectancy_Data.csv")
# df1.info()
# df1.columns
# df1.describe()
# df1.isnull().any()
# df1.isnull().sum()
# df1.duplicated().any()
# print()

